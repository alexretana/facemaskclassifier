{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.video import VideoStream\n",
    "import imutils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caffe .prototxt and weights downloaded from https://github.com/LZQthePlane/Face-detection-base-on-ResnetSSD\n",
    "\n",
    "Pyimagesearch Notebooks used:\n",
    "\n",
    "[Face Detection](https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/)\n",
    "\n",
    "[Streaming Video Into OpenCV](https://www.pyimagesearch.com/2019/04/15/live-video-streaming-over-network-with-opencv-and-imagezmq/)\n",
    "\n",
    "[blob explaination](https://www.pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/)\n",
    "\n",
    "[OBS](https://obsproject.com/download) + [OBS virtual cam](https://obsproject.com/forum/resources/obs-virtualcam.949/)\n",
    "\n",
    "[How to use yolov3 with OpenCV](https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/)\n",
    "\n",
    "[Live Cam at bryant park in New York](https://www.webcamtaxi.com/en/usa/new-york/bryant-park.html)\n",
    "\n",
    "[Yolov3 pretrained for face detection](https://github.com/sthanhng/yoloface)\n",
    "\n",
    "\n",
    "# Caffe Loaded model, MobileNetSSD, image test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n",
      "[INFO] computing object detections...\n"
     ]
    }
   ],
   "source": [
    "#load serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(\"MobileNetSSD_deploy.prototxt\", \"MobileNetSSD_deploy10695.caffemodel\")\n",
    "\n",
    "# load input image and construct blob resized to 300x300\n",
    "image = cv2.imread('pedestriantestimg.jpg')\n",
    "(h, w) = image.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300) ), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "# pass blob through network, obtain detects and predictions\n",
    "print(\"[INFO] computing object detections...\")\n",
    "net.setInput(blob)\n",
    "detections = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over detects\n",
    "for face in range(0, detections.shape[2]):\n",
    "    # extract the confidence (i.e., probability) associated with the prediction\n",
    "    confidence = detections[0, 0, face, 2]\n",
    "    \n",
    "    #filter out weak detections\n",
    "    if confidence > 0.5:\n",
    "        #compute coordinates of bouding box\n",
    "        box = detections[0,0, face , 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        \n",
    "        # draw bouding box with probability label\n",
    "        text = \"{:.2f}%\".format(confidence * 100)\n",
    "        y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "        cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0,0,255), 2)\n",
    "\n",
    "#show the output image\n",
    "cv2.imshow(\"Output\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caffe Loaded model, MobileNetSSD, video stream test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n",
      "[INFO] starting video stream...\n"
     ]
    }
   ],
   "source": [
    "#load our model\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(\"MobileNetSSD_deploy.prototxt\", \"MobileNetSSD_deploy10695.caffemodel\")\n",
    "\n",
    "#initialize the video stream\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=1).start()\n",
    "time.sleep(2.0)\n",
    "\n",
    "# loop over frames from stream\n",
    "while True:\n",
    "    #grab frame and resize to max width of 400 pixels\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "    \n",
    "    # grab the frame dim and convert blob\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    \n",
    "    # pass blob through net and obtain detects and pred\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    \n",
    "    #loop through detects\n",
    "    for face in range(0, detections.shape[2]):\n",
    "        # extract confidence associated with pred\n",
    "        confidence = detections[0, 0, face, 2]\n",
    "        \n",
    "        #filter ot weak detectons\n",
    "        if confidence < 0.5:\n",
    "            continue\n",
    "            \n",
    "        # compute coordinates of bounding box\n",
    "        box = detections[0, 0, face, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        \n",
    "        # draw bonding box + probability label\n",
    "        text = \"{:.2f}%\".format(confidence * 100)\n",
    "        y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), (0,0,255), 2)\n",
    "        cv2.putText(frame, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0,0,255), 2)\n",
    "        \n",
    "    # show output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # if the 'q' key was pressed, break from loo\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOGDescriptor tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 6 original boxes, 6 after suppression\n"
     ]
    }
   ],
   "source": [
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "image = cv2.imread('pedestriantestimg.jpg')\n",
    "image = imutils.resize(image, width=min(400, image.shape[1]))\n",
    "\n",
    "orig = image.copy()\n",
    "\n",
    "(rects, weights) = hog.detectMultiScale(image, winStride=(4,4), padding=(8,8), scale=1.05)\n",
    "\n",
    "for (x,y,w,h) in rects:\n",
    "    cv2.rectangle(orig, (x,y), (x+w, y+h), (0,0,255), 2)\n",
    "    \n",
    "rects = np.array([[x,y,x+w, y+h] for (x,y,w,h) in rects])\n",
    "pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "\n",
    "for (xA, yA, xB, yB) in pick:\n",
    "    cv2.rectangle(image, (xA, yA), (xB, yB), (0,255,0), 2)\n",
    "    \n",
    "print(\"[INFO] {} original boxes, {} after suppression\".format(len(rects), len(pick)))\n",
    "\n",
    "cv2.imshow(\"Before NMS\", orig)\n",
    "cv2.imshow(\"After NMS\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=1).start()\n",
    "time.sleep(2.0)\n",
    "\n",
    "while True:\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=min(400, frame.shape[1]))\n",
    "    orig = frame.copy()\n",
    "    \n",
    "    \n",
    "    (rects, weights) = hog.detectMultiScale(frame, winStride=(4,4), padding=(8,8), scale=1.01)\n",
    "    for (x,y,w,h) in rects:\n",
    "        cv2.rectangle(orig, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "    \n",
    "    rects = np.array([[x,y,x+w,y+h] for (x,y,w,h) in rects])\n",
    "    pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "    \n",
    "    for (x1,y1,x2,y2) in pick:\n",
    "        cv2.rectangle(frame, (x1, y1), (x2,y2), (0,0,255), 2)\n",
    "        \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Orig\", orig)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolov4 Pretrained 80 classes (COCO dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n",
      "[INFO] computing object detections...\n",
      "[INFO] YOLO took 0.610000 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#load serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromDarknet(\"yolov4.cfg\", \"yolov4.weights\")\n",
    "\n",
    "#determine only the *output* layer names that we need from yolo\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# load input image and construct blob resized to 300x300\n",
    "image = cv2.imread('pedestriantestimg.jpg')\n",
    "(h, w) = image.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(cv2.resize(image, (416, 416) ), 1/ 255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "# pass blob through network, obtain detects and predictions\n",
    "print(\"[INFO] computing object detections...\")\n",
    "net.setInput(blob)\n",
    "start = time.time()\n",
    "layerOutputs = net.forward(ln)\n",
    "end = time.time()\n",
    "\n",
    "print(\"[INFO] YOLO took {:.6f} seconds\".format(end - start))\n",
    "\n",
    "#initilize lists of detects bounding boxes, confidences, and class IDs\n",
    "boxes = []\n",
    "confidences = []\n",
    "classIDs = []\n",
    "\n",
    "for output in layerOutputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:]\n",
    "        classID = np.argmax(scores)\n",
    "        confidence = scores[classID]\n",
    "        \n",
    "        if confidence > 0.5:\n",
    "            box = detection[0:4] * np.array([w, h, w, h])\n",
    "            (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "            \n",
    "            x = int(centerX - (width/2))\n",
    "            y = int(centerY - (height/2))\n",
    "            \n",
    "            boxes.append([x, y, int(width), int(height)])\n",
    "            confidences.append(float(confidence))\n",
    "            classIDs.append(classID)\n",
    "         \n",
    "#apply non-maxima suppresion\n",
    "\n",
    "idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.3)\n",
    "\n",
    "if len(idxs) > 0:\n",
    "    for obj in idxs.flatten():\n",
    "        (x, y) = (boxes[obj][0], boxes[obj][1])\n",
    "        (w, h) = (boxes[obj][2], boxes[obj][3])\n",
    "        \n",
    "        color = [int(c) for c in COLORS[classIDs[obj]]]\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), color, 2)\n",
    "        text = \"{}: {:.4f}\".format(LABELS[classIDs[obj]], confidences[obj])\n",
    "        cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        \n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.video import VideoStream\n",
    "import imutils\n",
    "import time\n",
    "\n",
    "labelsPath = \"./coco.names\"\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "\n",
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromDarknet(\"yolov4.cfg\", \"yolov4.weights\")\n",
    "\n",
    "#determine only the *output* layer names that we need from yolo\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "from imutils.video import VideoStream\n",
    "vs = VideoStream(src=1).start()\n",
    "\n",
    "while True:\n",
    "    frame = vs.read()  \n",
    "\n",
    "    # load input image and construct blob resized to 300x300\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (608, 608) ), 1/ 255.0, (608, 608), swapRB=True, crop=False)\n",
    "\n",
    "    # pass blob through network, obtain detects and predictions\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(ln)\n",
    "\n",
    "    #initilize lists of detects bounding boxes, confidences, and class IDs\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "\n",
    "\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "        \n",
    "            if confidence > 0.6:\n",
    "                box = detection[0:4] * np.array([w, h, w, h])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "            \n",
    "                x = int(centerX - (width/2))\n",
    "                y = int(centerY - (height/2))\n",
    "            \n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "         \n",
    "    #apply non-maxima suppresion\n",
    "\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.3)\n",
    "\n",
    "    if len(idxs) > 0:\n",
    "        for obj in idxs.flatten():\n",
    "            (x, y) = (boxes[obj][0], boxes[obj][1])\n",
    "            (w, h) = (boxes[obj][2], boxes[obj][3])\n",
    "        \n",
    "            color = [int(c) for c in COLORS[classIDs[obj]]]\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            text = \"{}: {:.4f}\".format(LABELS[classIDs[obj]], confidences[obj])\n",
    "            cv2.putText(frame, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n",
    "vs.stream.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolov3 pretrained on face detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF_THRESHOLD = 0.5\n",
    "NMS_THRESHOLD = 0.4\n",
    "IMG_WIDTH = 416\n",
    "IMG_HEIGHT = 416\n",
    "\n",
    "# Default colors\n",
    "COLOR_BLUE = (255, 0, 0)\n",
    "COLOR_GREEN = (0, 255, 0)\n",
    "COLOR_RED = (0, 0, 255)\n",
    "COLOR_WHITE = (255, 255, 255)\n",
    "COLOR_YELLOW = (0, 255, 255)\n",
    "\n",
    "\n",
    "def get_outputs_names(net):\n",
    "    # Get the names of all the layers in the network\n",
    "    layers_names = net.getLayerNames()\n",
    "\n",
    "    # Get the names of the output layers, i.e. the layers with unconnected\n",
    "    # outputs\n",
    "    return [layers_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Draw the predicted bounding box\n",
    "def draw_predict(frame, conf, left, top, right, bottom):\n",
    "    # Draw a bounding box.\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), COLOR_YELLOW, 2)\n",
    "\n",
    "    text = '{:.2f}'.format(conf)\n",
    "\n",
    "    # Display the label at the top of the bounding box\n",
    "    label_size, base_line = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "\n",
    "    top = max(top, label_size[1])\n",
    "    cv2.putText(frame, text, (left, top - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.4,\n",
    "                COLOR_WHITE, 1)\n",
    "    \n",
    "def refined_box(left, top, width, height):\n",
    "    right = left + width\n",
    "    bottom = top + height\n",
    "\n",
    "    original_vert_height = bottom - top\n",
    "    top = int(top + original_vert_height * 0.15)\n",
    "    bottom = int(bottom - original_vert_height * 0.05)\n",
    "\n",
    "    margin = ((bottom - top) - (right - left)) // 2\n",
    "    left = left - margin if (bottom - top - right + left) % 2 == 0 else left - margin - 1\n",
    "\n",
    "    right = right + margin\n",
    "\n",
    "    return left, top, right, bottom\n",
    "\n",
    "def crop_pic(frame, left, top, right, bottom):\n",
    "    frame = frame[top:bottom+1, left: right+1]\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(\"yolov3-face.cfg\", \"yolov3-wider_16000.weights\")\n",
    "    \n",
    "image = cv2.imread('profpicalex.jpg')\n",
    "image = imutils.resize(image, width=1000)\n",
    "(h, w) = image.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(cv2.resize(image, (416, 416)), 1/255.0, (416,416), crop=False)\n",
    "\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "net.setInput(blob)\n",
    "Outs = net.forward(ln)    \n",
    "\n",
    "\n",
    "confidences = []\n",
    "boxes = []\n",
    "final_boxes = []\n",
    "for out in Outs:\n",
    "    for detection in out:\n",
    "        scores  = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * w)\n",
    "            center_y = int(detection[1] * h)\n",
    "            width = int(detection[2] * w)\n",
    "            height = int(detection[3] * h)\n",
    "            left = int(center_x - width/2)\n",
    "            top = int(center_y - height/2)\n",
    "            confidences.append(float(confidence))\n",
    "            boxes.append([left, top, width, height])\n",
    "        \n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.3)\n",
    "\n",
    "for i in indices:\n",
    "    i = i[0]\n",
    "    box = boxes[i]\n",
    "    left = box[0]\n",
    "    top = box[1]\n",
    "    width = box[2]\n",
    "    height = box[3]\n",
    "    final_boxes.append(box)\n",
    "    left, top, right, bottom = refined_box(left, top, width, height)\n",
    "    draw_predict(image, confidences[i], left, top, right, bottom)\n",
    "    crop = crop_pic(image, left, top, right, bottom)\n",
    "    \n",
    "    \n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Crop\", crop)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9731691"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507, 85)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
