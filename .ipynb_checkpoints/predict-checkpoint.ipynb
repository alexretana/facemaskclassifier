{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicitions Demonstration\n",
    "\n",
    "This notebook briefly workouts the details of getting a predicition pipeline that utilizes face detection, followed by mask classifaction. This demonstration will produce 4 images with classifications added which will be reviewed in the README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables would be declared at the top of a prediction file or inside a configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Constants #\n",
    "ORIG_INPUT_DATASET = \"mask-classifier-images\"\n",
    "BASE_PATH = \"dataset\"\n",
    "\n",
    "# attached to path below\n",
    "TRAIN = \"training\"\n",
    "TEST = \"evaluation\"\n",
    "VAL = \"validation\"\n",
    "\n",
    "# classes and color coding\n",
    "CLASSES = [\"Mask\", \"No_Mask\"]\n",
    "CLASS_COLORS = [(0,255,0),(0, 0, 255)]\n",
    "\n",
    "# Path for Label encoder\n",
    "LE_PATH = os.path.sep.join([\"output\", \"le.cpickle\"])\n",
    "BASE_CSV_PATH = \"output\"\n",
    "\n",
    "# model path\n",
    "MODEL_PATH = os.path.sep.join([\"output\", \"maskclassifier.model\"])\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These function are defined for the main funciton, as well as the colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default colors\n",
    "COLOR_BLUE = (255, 0, 0)\n",
    "COLOR_GREEN = (0, 255, 0)\n",
    "COLOR_RED = (0, 0, 255)\n",
    "COLOR_WHITE = (255, 255, 255)\n",
    "COLOR_YELLOW = (0, 255, 255)\n",
    "\n",
    "# Draw the predicted bounding box\n",
    "def draw_predict(frame, conf, left, top, right, bottom, classidx):\n",
    "    # Draw a bounding box.\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), CLASS_COLORS[classidx], 2)\n",
    "\n",
    "    text = '{}: {:.2f}%'.format(CLASSES[classidx], conf * 100)\n",
    "\n",
    "    # Display the label at the top of the bounding box\n",
    "    label_size, base_line = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "\n",
    "    top = max(top, label_size[1])\n",
    "    cv2.putText(frame, text, (left, top - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.4,\n",
    "                CLASS_COLORS[classidx], 1)\n",
    "    #print('drew something on output')\n",
    "    \n",
    "def refined_box(left, top, width, height):\n",
    "    right = left + width\n",
    "    bottom = top + height\n",
    "\n",
    "    original_vert_height = bottom - top\n",
    "    top = int(top + original_vert_height * 0.15)\n",
    "    bottom = int(bottom - original_vert_height * 0.05)\n",
    "\n",
    "    margin = ((bottom - top) - (right - left)) // 2\n",
    "    left = left - margin if (bottom - top - right + left) % 2 == 0 else left - margin - 1\n",
    "\n",
    "    right = right + margin\n",
    "\n",
    "    return left, top, right, bottom\n",
    "\n",
    "def crop_pic(frame, left, top, right, bottom):\n",
    "    frame = frame[top:bottom+1, left: right+1]\n",
    "    return frame\n",
    "\n",
    "def maskPredict(model, image):\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    #forward pass the image through\n",
    "    preds = model.predict(np.expand_dims(image,axis=0))[0]\n",
    "    i = np.argmax(preds)\n",
    "\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test image preperation for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define path to image for testing\n",
    "img_path = \"facewithmask.jpg\"\n",
    "\n",
    "#make clone of image to draw on later. Extract resolution for scaling later\n",
    "image = cv2.imread(img_path)\n",
    "output = image.copy()\n",
    "output = imutils.resize(output, width=400)\n",
    "(h, w) = output.shape[:2]\n",
    "\n",
    "# convert image's color, and create blob for face detection, create image copy to crop from later\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "blob4Face = cv2.dnn.blobFromImage(cv2.resize(image, (416,416)), 1/255.0, (416,416), crop=False)\n",
    "\n",
    "# convert the image to a floats and subtract mean. This will be passed to mask detection\n",
    "image = image.astype(\"float32\")\n",
    "mean = np.array([123.68, 116.779, 103.939][::-1], dtype=\"float32\")\n",
    "image -= mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One run through example, to be turned into a function in the next cell following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading mask classifier model...\n",
      "[INFO] loading face detection model...\n",
      "[[4]]\n",
      "drew something on output\n"
     ]
    }
   ],
   "source": [
    "#define path to image for testing\n",
    "img_path = \"facewithmask.jpg\"\n",
    "\n",
    "#make clone of image to draw on later. Extract resolution for scaling later\n",
    "image = cv2.imread(img_path)\n",
    "output = image.copy()\n",
    "output = imutils.resize(output, width=400)\n",
    "(h, w) = output.shape[:2]\n",
    "\n",
    "# convert image's color, and create blob for face detection, create image copy to crop from later\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "blob4Face = cv2.dnn.blobFromImage(cv2.resize(image, (416,416)), 1/255.0, (416,416), crop=False)\n",
    "\n",
    "# convert the image to a floats and subtract mean. This will be passed to mask detection\n",
    "image = image.astype(\"float32\")\n",
    "mean = np.array([123.68, 116.779, 103.939][::-1], dtype=\"float32\")\n",
    "image -= mean\n",
    "\n",
    "# load trained model from disk\n",
    "print(\"[INFO] loading mask classifier model...\")\n",
    "mask_model = load_model(MODEL_PATH)\n",
    "\n",
    "# load the model and get layer names for the output layers\n",
    "print(\"[INFO] loading face detection model...\")\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(\"models/yolov3-face.cfg\", \"models/yolov3-wider_16000.weights\")\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# forward pass the net after inputing imgage. Out only includes unconnected output layers\n",
    "net.setInput(blob4Face)\n",
    "Outs = net.forward(ln)\n",
    "\n",
    "#\n",
    "confidences = []\n",
    "boxes = []\n",
    "final_boxes = []\n",
    "for out in Outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * w)\n",
    "            center_y = int(detection[1] * h)\n",
    "            width = int(detection[2] * w)\n",
    "            height = int(detection[3] * h)\n",
    "            left = int(center_x - width/2)\n",
    "            top = int(center_y - height/2)\n",
    "            confidences.append(float(confidence))\n",
    "            boxes.append([left, top, width, height])\n",
    "\n",
    "# choose best choices out of overlapped boxes\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.3)\n",
    "\n",
    "print(indices)\n",
    "# this loop runs mask prediction and draws results to image\n",
    "for i in indices:\n",
    "    i = i[0]\n",
    "    box = boxes[i]\n",
    "    left = box[0]\n",
    "    top = box[1]\n",
    "    width = box[2]\n",
    "    height = box[3]\n",
    "    final_boxes.append(box)\n",
    "    left, top, right, bottom = refined_box(left, top, width, height)\n",
    "    crop = crop_pic(cv2.resize(image, (w, h)), left, top, right, bottom)\n",
    "    cv2.imshow(\"Crop\", crop)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    classidx = maskPredict(mask_model, crop)\n",
    "    draw_predict(output, confidences[i], left, top, right, bottom, classidx)\n",
    "    \n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.imshow(\"Crop\", crop)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicitonPipeline(img_path):\n",
    "    #make clone of image to draw on later. Extract resolution for scaling later\n",
    "    image = cv2.imread(img_path)\n",
    "    output = image.copy()\n",
    "    output = imutils.resize(output, width=400)\n",
    "    (h, w) = output.shape[:2]\n",
    "\n",
    "    # convert image's color, and create blob for face detection, create image copy to crop from later\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    blob4Face = cv2.dnn.blobFromImage(cv2.resize(image, (416,416)), 1/255.0, (416,416), crop=False)\n",
    "\n",
    "    # convert the image to a floats and subtract mean. This will be passed to mask detection\n",
    "    image = image.astype(\"float32\")\n",
    "    mean = np.array([123.68, 116.779, 103.939][::-1], dtype=\"float32\")\n",
    "    image -= mean\n",
    "\n",
    "    # load trained model from disk\n",
    "    print(\"[INFO] loading mask classifier model...\")\n",
    "    mask_model = load_model(MODEL_PATH)\n",
    "\n",
    "    # load the model and get layer names for the output layers\n",
    "    print(\"[INFO] loading face detection model...\")\n",
    "\n",
    "    net = cv2.dnn.readNetFromDarknet(\"models/yolov3-face.cfg\", \"models/yolov3-wider_16000.weights\")\n",
    "    ln = net.getLayerNames()\n",
    "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    # forward pass the net after inputing imgage. Out only includes unconnected output layers\n",
    "    net.setInput(blob4Face)\n",
    "    Outs = net.forward(ln)\n",
    "\n",
    "    #\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    final_boxes = []\n",
    "    for out in Outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0] * w)\n",
    "                center_y = int(detection[1] * h)\n",
    "                width = int(detection[2] * w)\n",
    "                height = int(detection[3] * h)\n",
    "                left = int(center_x - width/2)\n",
    "                top = int(center_y - height/2)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([left, top, width, height])\n",
    "\n",
    "    # choose best choices out of overlapped boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # this loop runs mask prediction and draws results to image\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        left = box[0]\n",
    "        top = box[1]\n",
    "        width = box[2]\n",
    "        height = box[3]\n",
    "        final_boxes.append(box)\n",
    "        left, top, right, bottom = refined_box(left, top, width, height)\n",
    "        crop = crop_pic(cv2.resize(image, (w, h)), left, top, right, bottom)\n",
    "        classidx = maskPredict(mask_model, crop)\n",
    "        draw_predict(output, confidences[i], left, top, right, bottom, classidx)\n",
    "\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.imshow(\"Output\", output)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final cell runs algorithm on demo images and places them in a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading mask classifier model...\n",
      "[INFO] loading face detection model...\n",
      "[INFO] loading mask classifier model...\n",
      "[INFO] loading face detection model...\n",
      "[INFO] loading mask classifier model...\n",
      "[INFO] loading face detection model...\n",
      "[INFO] loading mask classifier model...\n",
      "[INFO] loading face detection model...\n",
      "WARNING:tensorflow:5 out of the last 21 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002DF8A5A9378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "image_list = ['demo_image_1','demo_image_2','demo_image_3','demo_image_4']\n",
    "\n",
    "\n",
    "for img in image_list:\n",
    "    img_path = img + '.jpg'\n",
    "    output = predicitonPipeline(img_path)\n",
    "    processed_path = 'images/' + img + '(processed).jpg'\n",
    "    cv2.imwrite(processed_path ,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
